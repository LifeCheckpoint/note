<style>
* {
  box-sizing: border-box;
}
html {
  overflow: hidden;
}
body {
  overflow: hidden;
  margin: 0;
  font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
  height: 100vh;
  background: #111;
}
.g-absolute {
  position: absolute;
  top: 0px;
  left: 0px;
  width: 100%;
  height: 100%;
  overflow: hidden;
}
.fg-label {
  margin: 0;
  position: absolute;
  left: 0;
  width: 20px;
  color: #fff;
  text-shadow: 0 0 2px #aaa;
  transform: translateY(-50%);
  /* text-align: center; */
}
.bg-rule {
  position: absolute;
  border-top: 1px solid #aaa;
  width: calc(100% - 20px);
  left: 20px;
}
.canvas {
  display: block;
  transform-origin: 0 0;
  /* border: 4px solid #fff; */
}
.btn-main {
  position: absolute;
  top: calc(50% - 40px);
  left: calc(50% - 40px);
  width: 80px;
  height: 80px;
  line-height: 80px;
  color: #fff;
  background-color: rgba(255, 255, 255, .3);
  border-radius: 50%;
  border: none;
  font-size: 40px;
  text-align: center;
  cursor: pointer;
  transition: background-color .3s;
}
.btn-main:hover {
  background-color: rgba(255, 255, 255, .4);
}
.icon-start {
  display: inline-block;
  width: 0;
  height: 0;
  border-left: 36px solid #fff;
  border-top: 18px solid transparent;
  border-bottom: 18px solid transparent;
  margin-left: 8px;
}
.icon-stop {
  display: inline-block;
  width: 28px;
  height: 28px;
  background-color: #fff;
}
.status {
  position: absolute;
  right: 0;
  top: 0;
  color: rgba(255, 255, 255, .8);
  width: 120px;
  overflow: hidden;
}
</style>

<div class="bg g-absolute"></div>
<canvas class="canvas g-absolute"></canvas>
<div class="fg g-absolute"></div>
<button class="btn-main"><span class="icon-start" aria-label="start"></span></button>
<span class="status"></span>
<span class="pitchy"></span>

<script type="module">
import { PitchDetector } from 'https://esm.sh/pitchy@4'

const $ = el => document.querySelector(el)
/** @type {HTMLCanvasElement} */
const $canvas = $('.canvas')
const $btnMain = $('.btn-main')
const $status = $('.status')
const $bg = $('.bg')
const $fg = $('.fg')

const ctx = $canvas.getContext('2d', { willReadFrequently: true })
let image
const labels = ['A', 'G♯', 'G', 'F♯', 'F', 'E', 'D♯', 'D', 'C♯', 'C', 'B', 'A♯', 'A', 'G♯']

const Utils = {
  // hsl 的范围为 [0, 1]
  // rgb 的范围为 [0, 255]
  hsl2rgb ([h, s, l]) {
    h = h % 1 * 6
    // h = h % 360 / 60
    const c = s * (1 - Math.abs(2 * l - 1))
    const x = c * (1 - Math.abs(h % 2 - 1))
    const rgb = [0, 0, 0]
    const i = h / 2 | 0
    const j = h % 2 | 0
    rgb[(i + j) % 3] = c
    rgb[(i + 1 - j) % 3] = x
    return rgb.map(v => Math.round((v + l - c / 2) * 255))
  },
}

const initConfig = (config) => {
  config.a0 = config.a4 / 16 // lowest note on a piano
  config.c8 = config.a4 * Math.pow(2, 3.25) // highest note on a piano
  return config
}

const Tuner = {
  isInit: false,
  isStart: false,
  config: initConfig({
    a4: 440,
    smoothingTimeConstant: 0.8,
    // sampleRate: 1 << 13, // 采样率是 fftSize 的倍数时会造成频率空洞
    sampleRate: 44100,
    fftSize: 1 << 14,
    speed: 3, // 图像平移速度
    minVolumeDecibels: -1000,
  }),
  /** @type {AudioContext} */
  context: undefined,
  /** @type {MediaStream} */
  stream: undefined,
  /** @type {BiquadFilterNode} */
  node: undefined,
  /** @type {AnalyserNode} */
  analyser: undefined,
  // https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData
  // The frequencies are spread linearly from 0 to 1/2 of the sample rate.
  /** @type {Uint8Array} */
  frequencyData: undefined,
  detector: undefined,
  /** @type {Float32Array} */
  timeData: undefined,
  frameId: 0,
  status: {
    lastTime: 0,
    delta: 0,
    pitch: 0,
    clarity: 0,
    busy: undefined,
    update () {
      if (this.busy) return
      this.busy = setTimeout(() => {
        this.busy = undefined
      }, 300)
      $status.innerText = [
        'FPS: ' + (1000 / this.delta | 0),
        'Pitch: ' + this.pitch.toFixed(2),
        'Clarity: ' + (this.clarity * 100).toFixed(2) + '%',
      ].join('\n')
    }
  },
  init () {
    const { config } = Tuner
    Tuner.context = new AudioContext() // ({ sampleRate: config.sampleRate })
    config.sampleRate = Tuner.context.sampleRate
    Tuner.analyser = new AnalyserNode(Tuner.context, { fftSize: config.fftSize, smoothingTimeConstant: config.smoothingTimeConstant })
    Tuner.node = Tuner.analyser

    // const highpass = new BiquadFilterNode(Tuner.context, { type: 'highpass', frequency: config.a0 })
    // const lowpass = new BiquadFilterNode(Tuner.context, { type: 'lowpass', frequency: config.c8 })
    // lowpass.connect(highpass).connect(analyser)
    // Tuner.node = lowpass

    const len = Tuner.analyser.frequencyBinCount
    Tuner.frequencyData = new Uint8Array(len)
    Tuner.displayLength = config.c8 * 2 / config.sampleRate * len | 0

    Tuner.detector = PitchDetector.forFloat32Array(config.fftSize)
    Tuner.detector.minVolumeDecibels = config.minVolumeDecibels
    Tuner.timeData = new Float32Array(Tuner.detector.inputLength)

    Tuner.isInit = true
  },
  async start () {
    if (!Tuner.isInit) Tuner.init()
    Tuner.stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    const source = Tuner.context.createMediaStreamSource(Tuner.stream)
    // source -> lowpass -> highpass -> analyser
    source.connect(Tuner.node)
    Tuner.isStart = true
    Tuner.startRender()
  },
  stop () {
    cancelAnimationFrame(Tuner.frameId)
    Tuner.stream.getTracks().forEach(track => track.stop())
    Tuner.stream.removeTrack(Tuner.stream.getAudioTracks()[0])
    Tuner.isStart = false
  },
  getData () {
    Tuner.analyser.getByteFrequencyData(Tuner.frequencyData)
    Tuner.analyser.getFloatTimeDomainData(Tuner.timeData)
    const [pitch, clarity] = Tuner.detector.findPitch(Tuner.timeData, Tuner.config.sampleRate)
    Tuner.status.pitch = pitch
    Tuner.status.clarity = clarity
  },
  async mockStart () {
    const len = Tuner.config.fftSize / 2
    Tuner.frequencyData = new Uint8Array(len)
    Tuner.displayLength = len
    Tuner.isStart = true
    Tuner.startRender()
  },
  mockStop () {
    cancelAnimationFrame(Tuner.frameId)
    Tuner.isStart = false
  },
  mockGetData() {
    const index = Tuner.displayLength * Math.random() | 0
    Tuner.frequencyData[index] = 255 * Math.random() | 0
  },
  startRender () {
    if (Tuner.isStart) Tuner.frameId = requestAnimationFrame(Tuner.render)
  },
  getL (H) {
    const { a0, c8, sampleRate } = Tuner.config
    const data = Tuner.frequencyData

    let beta = 1
    if (Tuner.status.clarity > 0.9) {
      const value = Math.log2(Tuner.status.pitch / a0) % 1
      const diff = Math.abs(value - H)
      // if (diff < 2e-3) return 1 - 200*diff
      if (diff < 2e-3) beta = 500*diff
    }

    let L = 0
    let k = 1
    for (let f = a0 * Math.pow(2, H); f <= c8; f *= 2, k -= 0.1) {
      const value = data.length * f * 2 / sampleRate
      const index = value | 0
      let alpha = value - index
      alpha = alpha * alpha * (3 - 2 * alpha) // smoothstep
      L += (1-alpha) * data[index] + alpha * data[index+1]
      L += data[index] * k
    }
    L = Math.min((Math.pow((L / 255 - 1), 3) + 1) * 0.25, 0.8)
    return beta * L + (1 - beta)

    // const index = Tuner.displayLength * H | 0
    // let L = Tuner.frequencyData[index] / 255 // [0, 1]
    // return Math.min(0.8, 1.25 * L)
  },
  render (time) {
    Tuner.startRender()
    Tuner.getData()
    Tuner.status.delta = time - Tuner.status.lastTime
    Tuner.status.lastTime = time
    Tuner.status.update()

    const { width, height } = $canvas
    const speed = Tuner.config.speed
    for (let i = 0; i < image.data.length; i += 4) {
      const y = i / 4 / width | 0
      const x = i / 4 - y * width
      // 向左平移 speed * 1px
      if (x < width - 3) {
        image.data[i] = image.data[i + 4 * speed]
        image.data[i + 1] = image.data[i + 4 * speed + 1]
        image.data[i + 2] = image.data[i + 4 * speed + 2]
        image.data[i + 3] = image.data[i + 4 * speed + 3]
      } else {
        // 提取频谱
        const H = 1 - (y+1)*(labels.length - 1) / (height*12)
        const S = 1
        const L = Tuner.getL(H)
        const [r, g, b] = Utils.hsl2rgb([H, S, L])
        image.data[i] = r
        image.data[i + 1] = g
        image.data[i + 2] = b
        image.data[i + 3] = Math.round(L * 255)
      }
    }
    ctx.putImageData(image, 0, 0)
  },
  async onToggle () {
    try {
      await (Tuner.isStart ? Tuner.stop() : Tuner.start())
    } catch (err) {
      console.error(err)
      window.alert(err)
      return
    }
    $btnMain.innerHTML = Tuner.isStart ? '<span class="icon-stop" aria-label="stop"></span>' : '<span class="icon-start" aria-label="start"></span>'
  },
  onResize () {
    // const dpr = window.devicePixelRatio
    const dpr = 1
    $canvas.width = $canvas.style.width = window.innerWidth * dpr
    $canvas.height = $canvas.style.height = window.innerHeight * dpr
    $canvas.style.transform = `scale(${1 / dpr})`
    // ctx.clearRect(0, 0, $canvas.width, $canvas.height)
    image = ctx.getImageData(0, 0, $canvas.width, $canvas.height)
  },
  initBg () {
    for (let i = 0; i < labels.length; ++i) {
      const top = (i * 100 / (labels.length - 1)).toFixed(2) + '%'
      const rule = document.createElement('div')
      rule.className = 'bg-rule'
      rule.style.top = top
      $bg.appendChild(rule)

      const label = document.createElement('div')
      label.innerText = labels[i]
      label.className = 'fg-label'
      label.style.top = top
      $fg.appendChild(label)
    }
  },
}

const mock = false
if (mock) {
  Tuner.start = Tuner.mockStart
  Tuner.stop = Tuner.mockStop
  Tuner.getData = Tuner.mockGetData
}

$btnMain.onclick = Tuner.onToggle
window.onresize = Tuner.onResize

Tuner.initBg()
Tuner.onResize()
</script>
